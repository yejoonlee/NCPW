{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TS_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNjiYlbsShuIHKPgVOLXy9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yejoonlee/NCPW/blob/main/NCPW_DL/classify_log/TS_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow==2.4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_gq9c58sqbxb",
        "outputId": "b656fbdd-5d20-43fc-ed1d-b9c4000e50c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.4.0\n",
            "  Using cached tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Collecting numpy~=1.19.2\n",
            "  Using cached numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.8.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.3.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.10.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.2.0)\n",
            "Installing collected packages: numpy, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.5 tensorflow-2.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kww-fDmFrJaf",
        "outputId": "8f72ae05-f177-4af4-8470-0cda5f2282bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: numpy\n",
            "Version: 1.19.5\n",
            "Summary: NumPy is the fundamental package for array computing with Python.\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: None\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: \n",
            "Required-by: xgboost, xarray, wordcloud, torchvision, torchtext, tifffile, thinc, Theano-PyMC, tensorflow, tensorflow-probability, tensorflow-hub, tensorflow-datasets, tensorboard, tables, statsmodels, spacy, sklearn-pandas, seaborn, scs, scipy, scikit-learn, scikit-image, resampy, qdldl, PyWavelets, python-louvain, pystan, pysndfile, pymc3, pyerfa, pyemd, pycocotools, pyarrow, plotnine, patsy, pandas, osqp, opt-einsum, opencv-python, opencv-contrib-python, numexpr, numba, nibabel, netCDF4, moviepy, mlxtend, mizani, missingno, matplotlib, matplotlib-venn, lightgbm, librosa, Keras-Preprocessing, kapre, jpeg4py, jaxlib, jax, imgaug, imbalanced-learn, imageio, hyperopt, holoviews, h5py, gym, gensim, folium, fix-yahoo-finance, fbprophet, fastprogress, fastdtw, fastai, fa2, ecos, daft, cvxpy, cupy-cuda111, cufflinks, cmdstanpy, cftime, Bottleneck, bokeh, blis, autograd, atari-py, astropy, arviz, altair, albumentations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# System related and data input controls\n",
        "import os\n",
        "\n",
        "# Data manipulation, visualization and useful functions\n",
        "import pandas as pd\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "pd.options.display.max_rows = 50\n",
        "pd.options.display.max_columns = 40\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Modeling algorithms\n",
        "# General(Statistics/Econometrics)\n",
        "from sklearn import preprocessing\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.tsa.api as smt\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from scipy import stats\n",
        "\n",
        "# Classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Model selection\n",
        "from sklearn.model_selection import train_test_split,cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Evaluation metrics\n",
        "# for classification\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# For Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Flatten, Dropout\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU"
      ],
      "metadata": {
        "id": "OkIMCBufxPhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### modify lagged values of X_test\n",
        "def feature_engineering_lag_modified(Y_test, X_test, target):\n",
        "    X_test_lm = X_test.copy()\n",
        "    for col in target:\n",
        "        X_test_lm[col] = Y_test.shift(1).values\n",
        "        X_test_lm[col].fillna(method='bfill', inplace=True)\n",
        "        X_test_lm[col] = Y_test.shift(2).values\n",
        "        X_test_lm[col].fillna(method='bfill', inplace=True)\n",
        "    return X_test_lm\n",
        "# target = ['count_lag1', 'count_lag2']\n",
        "# X_test_fe = feature_engineering_lag_modified(Y_test_fe, X_test_fe, target)\n",
        "\n",
        "### Data split of time series\n",
        "def datasplit_ts(raw, Y_colname, X_colname, criteria):\n",
        "    raw_train = raw.loc[raw.index < criteria,:]\n",
        "    raw_test = raw.loc[raw.index >= criteria,:]\n",
        "    Y_train = raw_train[Y_colname]\n",
        "    X_train = raw_train[X_colname]\n",
        "    Y_test = raw_test[Y_colname]\n",
        "    X_test = raw_test[X_colname]\n",
        "    print('Train_size:', raw_train.shape, 'Test_size:', raw_test.shape)\n",
        "    print('X_train:', X_train.shape, 'Y_train:', Y_train.shape)\n",
        "    print('X_test:', X_test.shape, 'Y_test:', Y_test.shape)\n",
        "    return X_train, X_test, Y_train, Y_test\n",
        "# X_train, X_test, Y_train, Y_test = datasplit_ts(raw_fe, Y_colname, X_colname, '2012-07-01')\n",
        "\n",
        "### extract non-multicollinearity variables by VIF \n",
        "def feature_engineering_XbyVIF(X_train, num_variables):\n",
        "    vif = pd.DataFrame()\n",
        "    vif['VIF_Factor'] = [variance_inflation_factor(X_train.values, i) \n",
        "                         for i in range(X_train.shape[1])]\n",
        "    vif['Feature'] = X_train.columns\n",
        "    X_colname_vif = vif.sort_values(by='VIF_Factor', ascending=True)['Feature'][:num_variables].values\n",
        "    return X_colname_vif\n",
        "# X_colname_vif = feature_engineering_XbyVIF(X_train_femm, 10)\n",
        "# X_colname_vif\n",
        "\n",
        "### Evaluation of 1 pair of set\n",
        "def evaluation(Y_real, Y_pred, graph_on=False):\n",
        "    loss_length = len(Y_real.values.flatten()) - len(Y_pred)\n",
        "    if loss_length != 0:\n",
        "        Y_real = Y_real[loss_length:]\n",
        "    if graph_on == True:\n",
        "        pd.concat([Y_real, pd.DataFrame(Y_pred, index=Y_real.index, columns=['prediction'])], axis=1).plot(kind='line', figsize=(20,6),\n",
        "                                                                                                           xlim=(Y_real.index.min(),Y_real.index.max()),\n",
        "                                                                                                           linewidth=3, fontsize=20)\n",
        "        plt.title('Time Series of Target', fontsize=20)\n",
        "        plt.xlabel('Index', fontsize=15)\n",
        "        plt.ylabel('Target Value', fontsize=15)\n",
        "    MAE = abs(Y_real.values.flatten() - Y_pred).mean()\n",
        "    MSE = ((Y_real.values.flatten() - Y_pred)**2).mean()\n",
        "    MAPE = (abs(Y_real.values.flatten() - Y_pred)/Y_real.values.flatten()*100).mean()\n",
        "    Score = pd.DataFrame([MAE, MSE, MAPE], index=['MAE', 'MSE', 'MAPE'], columns=['Score']).T\n",
        "    Residual = pd.DataFrame(Y_real.values.flatten() - Y_pred, index=Y_real.index, columns=['Error'])\n",
        "    return Score, Residual\n",
        "# Score_tr, Residual_tr = evaluation(Y_train, pred_tr_reg1, graph_on=True)\n",
        "\n",
        "\n",
        "### Evaluation of train/test pairs\n",
        "def evaluation_trte(Y_real_tr, Y_pred_tr, Y_real_te, Y_pred_te, graph_on=False):\n",
        "    Score_tr, Residual_tr = evaluation(Y_real_tr, Y_pred_tr, graph_on=graph_on)\n",
        "    Score_te, Residual_te = evaluation(Y_real_te, Y_pred_te, graph_on=graph_on)\n",
        "    Score_trte = pd.concat([Score_tr, Score_te], axis=0)\n",
        "    Score_trte.index = ['Train', 'Test']\n",
        "    return Score_trte, Residual_tr, Residual_te\n",
        "# Score_reg1, Resid_tr_reg1, Resid_te_reg1 = evaluation_trte(Y_train, pred_tr_reg1, Y_test, pred_te_reg1, graph_on=True)\n",
        "\n",
        "\n",
        "### Error analysis\n",
        "def error_analysis(Y_Data, Target_name, X_Data, graph_on=False):\n",
        "    for x in Target_name:\n",
        "        Target_name = x\n",
        "    X_Data = X_Data.loc[Y_Data.index]\n",
        "\n",
        "    if graph_on == True:\n",
        "        ##### Error Analysis(Plot)\n",
        "        Y_Data['RowNum'] = Y_Data.reset_index().index\n",
        "\n",
        "        # Stationarity(Trend) Analysis\n",
        "        sns.set(palette=\"muted\", color_codes=True, font_scale=2)\n",
        "        sns.lmplot(x='RowNum', y=Target_name, data=Y_Data, fit_reg='True', size=5.2, aspect=2, ci=99, sharey=True)\n",
        "        del Y_Data['RowNum']\n",
        "\n",
        "        # Normal Distribution Analysis\n",
        "        figure, axes = plt.subplots(figsize=(12,8))\n",
        "        sns.distplot(Y_Data[Target_name], norm_hist='True', fit=stats.norm, ax=axes)\n",
        "\n",
        "        # Lag Analysis\n",
        "        length = int(len(Y_Data[Target_name])/10)\n",
        "        figure, axes = plt.subplots(1, 4, figsize=(12,3))\n",
        "        pd.plotting.lag_plot(Y_Data[Target_name], lag=1, ax=axes[0])\n",
        "        pd.plotting.lag_plot(Y_Data[Target_name], lag=5, ax=axes[1])\n",
        "        pd.plotting.lag_plot(Y_Data[Target_name], lag=10, ax=axes[2])\n",
        "        pd.plotting.lag_plot(Y_Data[Target_name], lag=50, ax=axes[3])\n",
        "\n",
        "        # Autocorrelation Analysis\n",
        "        figure, axes = plt.subplots(2,1,figsize=(12,5))\n",
        "        sm.tsa.graphics.plot_acf(Y_Data[Target_name], lags=100, use_vlines=True, ax=axes[0])\n",
        "        sm.tsa.graphics.plot_pacf(Y_Data[Target_name], lags=100, use_vlines=True, ax=axes[1]) \n",
        "\n",
        "    ##### Error Analysis(Statistics)\n",
        "    # Checking Stationarity\n",
        "    # Null Hypothesis: The Time-series is non-stationalry\n",
        "    Stationarity = pd.Series(sm.tsa.stattools.adfuller(Y_Data[Target_name])[0:4],\n",
        "                             index=['Test Statistics', 'p-value', 'Used Lag', 'Used Observations'])\n",
        "    for key, value in sm.tsa.stattools.adfuller(Y_Data[Target_name])[4].items():\n",
        "        Stationarity['Critical Value(%s)'%key] = value\n",
        "        Stationarity['Maximum Information Criteria'] = sm.tsa.stattools.adfuller(Y_Data[Target_name])[5]\n",
        "        Stationarity = pd.DataFrame(Stationarity, columns=['Stationarity'])\n",
        "\n",
        "    # Checking of Normality\n",
        "    # Null Hypothesis: The residuals are normally distributed\n",
        "    Normality = pd.DataFrame([stats.shapiro(Y_Data[Target_name])],\n",
        "                             index=['Normality'], columns=['Test Statistics', 'p-value']).T\n",
        "\n",
        "    # Checking for Autocorrelation\n",
        "    # Null Hypothesis: Autocorrelation is absent\n",
        "    Autocorrelation = pd.concat([pd.DataFrame(sm.stats.diagnostic.acorr_ljungbox(Y_Data[Target_name], lags=[1,5,10,50])[0], columns=['Test Statistics']),\n",
        "                                 pd.DataFrame(sm.stats.diagnostic.acorr_ljungbox(Y_Data[Target_name], lags=[1,5,10,50])[1], columns=['p-value'])], axis=1).T\n",
        "    Autocorrelation.columns = ['Autocorr(lag1)', 'Autocorr(lag5)', 'Autocorr(lag10)', 'Autocorr(lag50)']\n",
        "\n",
        "    # Checking Heteroscedasticity\n",
        "    # Null Hypothesis: Error terms are homoscedastic\n",
        "    Heteroscedasticity = pd.DataFrame([sm.stats.diagnostic.het_goldfeldquandt(Y_Data[Target_name], X_Data.values, alternative='two-sided')],\n",
        "                                      index=['Heteroscedasticity'], columns=['Test Statistics', 'p-value', 'Alternative']).T\n",
        "    Score = pd.concat([Stationarity, Normality, Autocorrelation, Heteroscedasticity], join='outer', axis=1)\n",
        "    index_new = ['Test Statistics', 'p-value', 'Alternative', 'Used Lag', 'Used Observations',\n",
        "                 'Critical Value(1%)', 'Critical Value(5%)', 'Critical Value(10%)', 'Maximum Information Criteria']\n",
        "    Score.reindex(index_new)\n",
        "# error_analysis(Resid_tr_reg1[1:], ['Error'], X_train, graph_on=True)"
      ],
      "metadata": {
        "id": "SzEdwBSGx2kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P0Uw5VOvGCr",
        "outputId": "a295606e-006c-47ce-9f82-e01c654925ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /contents/; to attempt to forcibly remount, call drive.mount(\"/contents/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/contents/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.categorical import Categorical\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "b_skills = [\n",
        "    {'idx':0,\n",
        "     'name':'kick',\n",
        "     'damage':25,\n",
        "     'cool':2,\n",
        "     'hit_rate':0.9\n",
        "    },\n",
        "    {'idx':1,\n",
        "     'name':'punch',\n",
        "     'damage':10,\n",
        "     'cool':1,\n",
        "     'hit_rate':1.0\n",
        "    }\n",
        "]\n",
        "\n",
        "p_skills = [\n",
        "    {'idx':0,\n",
        "     'name':'kick',\n",
        "     'damage':25,\n",
        "     'cool':2,\n",
        "     'hit_rate':0.9\n",
        "    },\n",
        "    {'idx':1,\n",
        "     'name':'punch',\n",
        "     'damage':10,\n",
        "     'cool':1,\n",
        "     'hit_rate':1.0\n",
        "    },\n",
        "    {'idx':2,\n",
        "     'name':'heal',\n",
        "     'damage':0,\n",
        "     'cool':5,\n",
        "     'hit_rate':1.0\n",
        "    },\n",
        "    {'idx':3,\n",
        "     'name':'jump',\n",
        "     'damage':0,\n",
        "     'cool':1,\n",
        "     'hit_rate':1.0\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "class boss_raid_simulater():\n",
        "    def __init__(self, b_skills, p_skills, reward_rate):\n",
        "\n",
        "        self.reward_rate = reward_rate\n",
        "\n",
        "        self.full_hp = 100\n",
        "\n",
        "        self.num_bs = len(b_skills)\n",
        "        self.num_ps = len(p_skills)\n",
        "\n",
        "        self.state_dict = dict()\n",
        "        self.state_dict['b_hp'] = self.full_hp\n",
        "        for i in range(len(b_skills)):\n",
        "            self.state_dict[f'b_cool_{i}'] = 0\n",
        "        self.b_skills = b_skills\n",
        "\n",
        "        self.state_dict['p_hp'] = self.full_hp\n",
        "        for i in range(len(p_skills)):\n",
        "            self.state_dict[f'p_cool_{i}'] = 0\n",
        "        self.p_skills = p_skills\n",
        "\n",
        "        self.state = np.array(list(self.state_dict.values()))\n",
        "\n",
        "        self.boss_action = []\n",
        "        self.done = 0\n",
        "        self.len_t = 0\n",
        "\n",
        "        self.reward = 0\n",
        "\n",
        "    def observe(self):\n",
        "        return self.state\n",
        "\n",
        "    def step(self, p_action):\n",
        "        self.len_t += 1\n",
        "        len_t = self.len_t\n",
        "        p_skill = self.p_skills[int(p_action)]\n",
        "\n",
        "        b_action = int(np.random.uniform(0.0, 1.0, 1).round())\n",
        "        self.boss_action.append(b_action)\n",
        "        b_skill = self.b_skills[b_action]\n",
        "\n",
        "        #         self.battle(p_skill, b_skill)\n",
        "        self.battle_with_cool(p_skill, b_skill)\n",
        "\n",
        "        self.reward = (- self.state_dict['b_hp'] * self.reward_rate[0] + self.state_dict['p_hp'] * self.reward_rate[\n",
        "            1] - len_t * self.reward_rate[2])\n",
        "\n",
        "        if self.state_dict['b_hp'] <= 0 or self.state_dict['p_hp'] <= 0:\n",
        "            self.done = 1\n",
        "\n",
        "            if self.state_dict['b_hp'] <= 0:\n",
        "                self.reward += self.full_hp * max([self.reward_rate[0], self.reward_rate[1]]) * self.reward_rate[3]\n",
        "\n",
        "            if self.state_dict['p_hp'] <= 0:\n",
        "                self.reward -= self.full_hp * max([self.reward_rate[0], self.reward_rate[1]]) * self.reward_rate[3]\n",
        "\n",
        "        ns = self.observe()\n",
        "        r = self.reward\n",
        "        done = self.done\n",
        "\n",
        "        return ns, r, done\n",
        "\n",
        "    def battle_with_cool(self, p_skill, b_skill):\n",
        "        p_d = p_skill['damage']\n",
        "        b_d = b_skill['damage']\n",
        "\n",
        "        p_c = p_skill['cool']\n",
        "        b_c = b_skill['cool']\n",
        "\n",
        "        p_i = p_skill['idx']\n",
        "        b_i = b_skill['idx']\n",
        "\n",
        "        p_n = p_skill['name']\n",
        "\n",
        "        p_sc = self.state_dict[f'p_cool_{p_i}']\n",
        "        b_sc = self.state_dict[f'b_cool_{b_i}']\n",
        "\n",
        "        # print(f\"b:{b_skill['name']} / p:{p_skill['name']}\")\n",
        "\n",
        "        if b_sc == 0:\n",
        "            if p_n == 'jump':\n",
        "                if np.random.uniform(0.0, 1.0, 1) < 0.7:\n",
        "                    # print('miss')\n",
        "                    pass\n",
        "                else:\n",
        "                    self.state_dict['p_hp'] -= b_d\n",
        "            else:\n",
        "                self.state_dict['p_hp'] -= b_d\n",
        "            self.state_dict[f'b_cool_{b_i}'] = b_c + 1\n",
        "        for i in range(self.num_bs):\n",
        "            self.state_dict[f'b_cool_{i}'] = max([self.state_dict[f'b_cool_{i}'] - 1, 0])\n",
        "\n",
        "        if p_sc == 0:\n",
        "            if p_n == 'heal':\n",
        "                # print('healed')\n",
        "                self.state_dict['p_hp'] += 20\n",
        "            else:\n",
        "                self.state_dict['b_hp'] -= p_d\n",
        "            self.state_dict[f'p_cool_{p_i}'] = p_c + 1\n",
        "        for i in range(self.num_ps):\n",
        "            self.state_dict[f'p_cool_{i}'] = max([self.state_dict[f'p_cool_{i}'] - 1, 0])\n",
        "\n",
        "        self.state = np.array(list(self.state_dict.values()))\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 output_dim: int,\n",
        "                 num_neurons: list = [64, 32],\n",
        "                 hidden_act: str = 'ReLU',\n",
        "                 out_act: str = 'Identity'):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_neurons = num_neurons\n",
        "        self.hidden_act = getattr(nn, hidden_act)()\n",
        "        self.out_act = getattr(nn, out_act)()\n",
        "\n",
        "        input_dims = [input_dim] + num_neurons\n",
        "        output_dims = num_neurons + [output_dim]\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i, (in_dim, out_dim) in enumerate(zip(input_dims, output_dims)):\n",
        "            is_last = True if i == len(input_dims) - 1 else False\n",
        "            self.layers.append(nn.Linear(in_dim, out_dim))\n",
        "            if is_last:\n",
        "                self.layers.append(self.out_act)\n",
        "            else:\n",
        "                self.layers.append(self.hidden_act)\n",
        "\n",
        "    def forward(self, xs):\n",
        "        for layer in self.layers:\n",
        "            xs = layer(xs)\n",
        "        return xs\n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 state_dim: int,\n",
        "                 action_dim: int,\n",
        "                 qnet: nn.Module,\n",
        "                 qnet_target: nn.Module,\n",
        "                 lr: float,\n",
        "                 gamma: float,\n",
        "                 epsilon: float):\n",
        "        \"\"\"\n",
        "        :param state_dim: input state dimension\n",
        "        :param action_dim: action dimension\n",
        "        :param qnet: main q network\n",
        "        :param qnet_target: target q network\n",
        "        :param lr: learning rate\n",
        "        :param gamma: discount factor of MDP\n",
        "        :param epsilon: E-greedy factor\n",
        "        \"\"\"\n",
        "\n",
        "        super(DQN, self).__init__()\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.qnet = qnet\n",
        "        self.lr = lr\n",
        "        self.gamma = gamma\n",
        "        self.opt = torch.optim.Adam(params=self.qnet.parameters(), lr=lr)\n",
        "        self.register_buffer('epsilon', torch.ones(1) * epsilon)\n",
        "\n",
        "        # target network related\n",
        "        qnet_target.load_state_dict(qnet.state_dict())\n",
        "        self.qnet_target = qnet_target\n",
        "        self.criteria = nn.SmoothL1Loss()\n",
        "\n",
        "    def get_action(self, state):\n",
        "        qs = self.qnet(state)\n",
        "        prob = np.random.uniform(0.0, 1.0, 1)\n",
        "        if torch.from_numpy(prob).float() <= self.epsilon:  # random\n",
        "            action = np.random.choice(range(self.action_dim))\n",
        "        else:  # greedy\n",
        "            action = qs.argmax(dim=-1)\n",
        "        return int(action)\n",
        "\n",
        "    def update(self, state, action, reward, next_state, done):\n",
        "        s, a, r, ns = state, action, reward, next_state\n",
        "\n",
        "        # compute Q-Learning target with 'target network'\n",
        "        with torch.no_grad():\n",
        "            q_max, _ = self.qnet_target(ns).max(dim=-1, keepdims=True)\n",
        "            q_target = r + self.gamma * q_max * (1 - done)\n",
        "\n",
        "        q_val = self.qnet(s).gather(1, a)\n",
        "        loss = self.criteria(q_val, q_target)\n",
        "\n",
        "        self.opt.zero_grad()\n",
        "        loss.backward()\n",
        "        self.opt.step()\n",
        "\n",
        "\n",
        "from random import sample\n",
        "class ReplayMemory:\n",
        "    def __init__(self, max_size):\n",
        "        # deque object that we've used for 'episodic_memory' is not suitable for random sampling\n",
        "        # here, we instead use a fix-size array to implement 'buffer'\n",
        "        self.buffer = [None] * max_size\n",
        "        self.max_size = max_size\n",
        "        self.index = 0\n",
        "        self.size = 0\n",
        "\n",
        "    def push(self, obj):\n",
        "        self.buffer[self.index] = obj\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "        self.index = (self.index + 1) % self.max_size\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        indices = sample(range(self.size), batch_size)\n",
        "        return [self.buffer[index] for index in indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "from types import prepare_class\n",
        "def to_tensor(np_array: np.array, size=None) -> torch.tensor:\n",
        "    torch_tensor = torch.from_numpy(np_array).float()\n",
        "    if size is not None:\n",
        "        torch_tensor = torch_tensor.view(size)\n",
        "    return torch_tensor\n",
        "\n",
        "\n",
        "def to_numpy(torch_tensor: torch.tensor) -> np.array:\n",
        "    return torch_tensor.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "def prepare_training_inputs(sampled_exps, device='cpu'):\n",
        "    states = []\n",
        "    actions = []\n",
        "    rewards = []\n",
        "    next_states = []\n",
        "    dones = []\n",
        "    for sampled_exp in sampled_exps:\n",
        "        states.append(sampled_exp[0])\n",
        "        actions.append(sampled_exp[1])\n",
        "        rewards.append(sampled_exp[2])\n",
        "        next_states.append(sampled_exp[3])\n",
        "        dones.append(sampled_exp[4])\n",
        "\n",
        "    states = torch.cat(states, dim=0).float().to(device)\n",
        "    actions = torch.cat(actions, dim=0).to(device)\n",
        "    rewards = torch.cat(rewards, dim=0).float().to(device)\n",
        "    next_states = torch.cat(next_states, dim=0).float().to(device)\n",
        "    dones = torch.cat(dones, dim=0).float().to(device)\n",
        "    return states, actions, rewards, next_states, dones\n",
        "\n",
        "\n",
        "def get_agent_to_load(reward_rate, print_all=False, memory_size=1, batch_size=1, ):\n",
        "    env = boss_raid_simulater(b_skills, p_skills, reward_rate)\n",
        "    s_dim = env.state.shape[0]\n",
        "    a_dim = len(p_skills)\n",
        "\n",
        "    qnet = MLP(s_dim, a_dim, num_neurons=[64,64])\n",
        "    qnet_target = MLP(s_dim, a_dim, num_neurons=[64,64])\n",
        "\n",
        "    # initialize target network same as the main network.\n",
        "    qnet_target.load_state_dict(qnet.state_dict())\n",
        "    agent = DQN(s_dim, 1, qnet=qnet, qnet_target=qnet_target, lr=1e-4 * 5, gamma=0.88, epsilon=1.0)\n",
        "    memory = ReplayMemory(memory_size)\n",
        "\n",
        "    # epsilon scheduling\n",
        "    # slowly decaying_epsilon\n",
        "    epsilon = 0.8\n",
        "    agent.epsilon = torch.tensor(epsilon)\n",
        "    env = boss_raid_simulater(b_skills, p_skills, reward_rate)\n",
        "    s = env.observe()\n",
        "    cum_r = 0\n",
        "\n",
        "    while True:\n",
        "        s = to_tensor(s, size=(1, s_dim))\n",
        "        a = agent.get_action(s)\n",
        "        ns, r, done = env.step(a)\n",
        "\n",
        "        experience = (s,\n",
        "                      torch.tensor(a).view(1, 1),\n",
        "                      torch.tensor(r / 100.0).view(1, 1),\n",
        "                      torch.tensor(ns).view(1, s_dim),\n",
        "                      torch.tensor(done).view(1, 1))\n",
        "        memory.push(experience)\n",
        "\n",
        "        s = ns\n",
        "        cum_r += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # train agent\n",
        "    sampled_exps = memory.sample(batch_size)\n",
        "    sampled_exps = prepare_training_inputs(sampled_exps)\n",
        "    agent.update(*sampled_exps)\n",
        "\n",
        "    qnet_target.load_state_dict(qnet.state_dict())\n",
        "\n",
        "    return agent\n",
        "\n",
        "\n",
        "def load_agent(agent_name):\n",
        "    reward_rate = [0, 0, 0, 0]\n",
        "    agent_load = get_agent_to_load(reward_rate)\n",
        "    agent_load.load_state_dict(torch.load(agent_name))\n",
        "\n",
        "    return agent_load\n",
        "\n",
        "\n",
        "def get_single_play_log(agent):\n",
        "    reward_rate = [0, 0, 0, 0]\n",
        "    sum_wr = 0\n",
        "\n",
        "    log = {'states': [],\n",
        "           'p_actions': [],\n",
        "           'b_actions': [], }\n",
        "\n",
        "    env = boss_raid_simulater(b_skills, p_skills, reward_rate)\n",
        "    s_dim = env.state.shape[0]\n",
        "    a_dim = len(p_skills)\n",
        "    s = env.observe()\n",
        "    cum_r = 0\n",
        "\n",
        "    states = []\n",
        "    actions = []\n",
        "    rewards = []\n",
        "\n",
        "    while True:\n",
        "        s = to_tensor(s, size=(1, s_dim))\n",
        "        a = agent.get_action(s)\n",
        "        ns, r, done = env.step(a)\n",
        "\n",
        "        states.append(list(to_numpy(s)[0]))\n",
        "        actions.append(a)\n",
        "        rewards.append(r)\n",
        "\n",
        "        s = ns\n",
        "        cum_r += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    log['states'] = str(states)\n",
        "    log['p_actions'] = str(actions)\n",
        "    log['b_actions'] = str(env.boss_action)\n",
        "\n",
        "    return log"
      ],
      "metadata": {
        "id": "Kcw9S0h_vO3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_load_a = load_agent('/contents/MyDrive/Colab_Notebooks/projects/NCPW/RL/agent/DQN_agent_[10_10_20_20].ptb')\n",
        "agent_load_b = load_agent('/contents/MyDrive/Colab_Notebooks/projects/NCPW/RL/agent/DQN_agent_[10_15_20_20].ptb')\n",
        "agent_load_c = load_agent('/contents/MyDrive/Colab_Notebooks/projects/NCPW/RL/agent/DQN_agent_[20_15_20_20].ptb')"
      ],
      "metadata": {
        "id": "AB9ya33DvRqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logs = [[],[],[]]\n",
        "for _ in range(300):\n",
        "  log_a = json.loads(get_single_play_log(agent_load_a)['states'])\n",
        "  logs[0]+=log_a\n",
        "  log_b = json.loads(get_single_play_log(agent_load_b)['states'])\n",
        "  logs[1]+=log_b\n",
        "  log_c = json.loads(get_single_play_log(agent_load_c)['states'])\n",
        "  logs[2]+=log_c"
      ],
      "metadata": {
        "id": "wGhCIX73vWvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_a = pd.DataFrame(logs[0])\n",
        "df_b = pd.DataFrame(logs[1])\n",
        "df_c = pd.DataFrame(logs[2])                    "
      ],
      "metadata": {
        "id": "CoqmPc0Dyhzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round(df_a.shape[0]*0.1), round(df_b.shape[0]*0.1), round(df_c.shape[0]*0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oLqK9QN1zvi",
        "outputId": "7b6f4edb-f221-4efa-9017-e6f3669c4588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(356, 574, 391)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_a = df_a\n",
        "raw_b = df_b\n",
        "raw_c = df_c\n",
        "\n",
        "# Parameters\n",
        "criteria = df_a.shape[0] - round(df_a.shape[0]*0.1)\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "sequence = 4\n",
        "batch_size = 32\n",
        "epoch = 5\n",
        "verbose = 1\n",
        "dropout_ratio = 0\n",
        "\n",
        "# Feature Engineering\n",
        "## Train & Test Split\n",
        "train_a = raw_a.loc[raw_a.index < criteria,:]\n",
        "test_a = raw_a.loc[raw_a.index >= criteria,:]\n",
        "\n",
        "train_b = raw_b.loc[raw_b.index < criteria,:]\n",
        "test_b = raw_b.loc[raw_b.index >= criteria,:]\n",
        "\n",
        "train_c = raw_c.loc[raw_c.index < criteria,:]\n",
        "test_c = raw_c.loc[raw_c.index >= criteria,:]\n",
        "\n",
        "print('Train_size:', train_a.shape, 'Test_size:', test_a.shape)\n",
        "print('Train_size:', train_b.shape, 'Test_size:', test_b.shape)\n",
        "print('Train_size:', train_c.shape, 'Test_size:', test_c.shape)\n",
        "\n",
        "## Scaling\n",
        "train_a_scaled = scaler.fit_transform(train_a)\n",
        "test_a_scaled = scaler.transform(test_a)\n",
        "\n",
        "train_b_scaled = scaler.fit_transform(train_b)\n",
        "test_b_scaled = scaler.transform(test_b)\n",
        "\n",
        "train_c_scaled = scaler.fit_transform(train_c)\n",
        "test_c_scaled = scaler.transform(test_c)\n",
        "\n",
        "y_a = [1.0,0.0,0.0]\n",
        "y_b = [0.0,1.0,0.0]\n",
        "y_c = [0.0,0.0,1.0]\n",
        "\n",
        "## X / Y Split\n",
        "X_train, Y_train = [], []\n",
        "for index in range(len(train_a_scaled) - sequence):\n",
        "    X_train.append(train_a_scaled[index: index + sequence])\n",
        "    Y_train.append(y_a)\n",
        "\n",
        "    X_train.append(train_b_scaled[index: index + sequence])\n",
        "    Y_train.append(y_b)\n",
        "\n",
        "    X_train.append(train_c_scaled[index: index + sequence])\n",
        "    Y_train.append(y_c)\n",
        "\n",
        "X_test, Y_test = [], []\n",
        "for index in range(len(test_a_scaled) - sequence):\n",
        "    X_test.append(test_a_scaled[index: index + sequence])\n",
        "    Y_test.append(y_a)\n",
        "\n",
        "    X_test.append(test_b_scaled[index: index + sequence])\n",
        "    Y_test.append(y_b)\n",
        "    \n",
        "    X_test.append(test_c_scaled[index: index + sequence])\n",
        "    Y_test.append(y_c)\n",
        "\n",
        "\n",
        "# ## X / Y Split\n",
        "# X_train, Y_train = [], []\n",
        "# for index in range(len(train_a_scaled) - sequence):\n",
        "#     X_train.append(train_a_scaled[index: index + sequence])\n",
        "#     Y_train.append(y_a)\n",
        "\n",
        "# for index in range(len(train_a_scaled) - sequence):\n",
        "#     X_train.append(train_b_scaled[index: index + sequence])\n",
        "#     Y_train.append(y_b)\n",
        "\n",
        "# for index in range(len(train_a_scaled) - sequence):\n",
        "#     X_train.append(train_c_scaled[index: index + sequence])\n",
        "#     Y_train.append(y_c)\n",
        "\n",
        "# X_test_a, Y_test_a = [], []\n",
        "# for index in range(len(test_a_scaled) - sequence):\n",
        "#     X_test_a.append(test_a_scaled[index: index + sequence])\n",
        "#     Y_test_a.append(y_a)\n",
        "\n",
        "# X_test_b, Y_test_b = [], []\n",
        "# for index in range(len(test_a_scaled) - sequence):\n",
        "#     X_test_b.append(test_b_scaled[index: index + sequence])\n",
        "#     Y_test_b.append(y_b)\n",
        "    \n",
        "# X_test_c, Y_test_c = [], []\n",
        "# for index in range(len(test_a_scaled) - sequence):\n",
        "#     X_test_c.append(test_c_scaled[index: index + sequence])\n",
        "#     Y_test_c.append(y_c)\n",
        "\n",
        "\n",
        "# Retype and Reshape\n",
        "X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
        "X_test, Y_test = np.array(X_test), np.array(Y_test)\n",
        "\n",
        "print('X_train:', X_train.shape, 'Y_train:', Y_train.shape)\n",
        "print('X_test:', X_test.shape, 'Y_test:', Y_test.shape)\n",
        "\n",
        "# X_test_a, Y_test_a = np.array(X_test_a), np.array(Y_test_a)\n",
        "# X_test_b, Y_test_b = np.array(X_test_b), np.array(Y_test_b)\n",
        "# X_test_c, Y_test_c = np.array(X_test_c), np.array(Y_test_c)\n",
        "\n",
        "# print('X_train:', X_train.shape, 'Y_train:', Y_train.shape)\n",
        "# print('X_test:', X_test.shape, 'Y_test:', Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13I-HQzj8jnY",
        "outputId": "d72455d8-fab2-4b5f-a9c9-a4c08e7d1092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_size: (3200, 8) Test_size: (356, 8)\n",
            "Train_size: (3200, 8) Test_size: (2541, 8)\n",
            "Train_size: (3200, 8) Test_size: (708, 8)\n",
            "X_train: (9588, 4, 8) Y_train: (9588, 3)\n",
            "X_test: (1056, 4, 8) Y_test: (1056, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.array(X_test.tolist())\n",
        "X_test\n",
        "# X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zhO1hSsZJDi",
        "outputId": "a844678e-9b30-4746-cd13-fd461274ee7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.        , 0.        , 1.        , ..., 0.        ,\n",
              "         0.        , 1.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
              "         0.        , 1.        ],\n",
              "        [0.        , 1.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ]],\n",
              "\n",
              "       [[0.47368421, 0.        , 0.        , ..., 0.        ,\n",
              "         0.4       , 1.        ],\n",
              "        [0.47368421, 0.        , 1.        , ..., 0.        ,\n",
              "         0.2       , 0.        ],\n",
              "        [0.47368421, 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 1.        ],\n",
              "        [0.47368421, 0.        , 1.        , ..., 0.        ,\n",
              "         0.        , 0.        ]],\n",
              "\n",
              "       [[0.10526316, 0.        , 1.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.10526316, 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 1.        ],\n",
              "        [0.10526316, 1.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.10526316, 0.5       , 0.        , ..., 0.        ,\n",
              "         0.        , 1.        ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.33333333, 0.        , 1.        , ..., 0.        ,\n",
              "         0.4       , 1.        ],\n",
              "        [0.33333333, 1.        , 0.        , ..., 0.        ,\n",
              "         0.2       , 0.        ],\n",
              "        [0.        , 0.5       , 1.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 1.        ]],\n",
              "\n",
              "       [[0.21052632, 0.        , 0.        , ..., 0.        ,\n",
              "         0.6       , 0.        ],\n",
              "        [0.21052632, 0.        , 1.        , ..., 0.        ,\n",
              "         0.4       , 1.        ],\n",
              "        [0.21052632, 0.        , 0.        , ..., 0.        ,\n",
              "         0.2       , 0.        ],\n",
              "        [0.21052632, 1.        , 0.        , ..., 0.        ,\n",
              "         0.        , 1.        ]],\n",
              "\n",
              "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 1.        , 0.        , ..., 0.        ,\n",
              "         0.        , 1.        ],\n",
              "        [1.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.73684211, 1.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM\n",
        "# with tf.device('/device:GPU:0'):\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='relu'))\n",
        "model.add(Dropout(dropout_ratio)) \n",
        "# model.add(LSTM(128, return_sequences=True, activation=\"relu\"))\n",
        "# model.add(Dropout(dropout_ratio)) \n",
        "model.add(LSTM(16, return_sequences=False, activation=\"relu\"))\n",
        "model.add(Dropout(dropout_ratio)) \n",
        "model.add(Dense(3))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()\n",
        "model_fit = model.fit(X_train, Y_train, \n",
        "                      batch_size=batch_size, epochs=epoch,\n",
        "                      verbose=verbose)\n",
        "\n",
        "plt.plot(pd.DataFrame(model_fit.history))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# prediction\n",
        "Y_train_pred = model.predict(X_train)\n",
        "Y_test_pred = model.predict(X_test)\n",
        "\n",
        "# evaluation\n",
        "result = model.evaluate(X_test, Y_test_pred)\n",
        "# if scaler != []:\n",
        "#     Y_train = scaler.inverse_transform(Y_train)\n",
        "#     Y_train_pred = scaler.inverse_transform(Y_train_pred)\n",
        "#     Y_test = scaler.inverse_transform(Y_test)\n",
        "#     Y_test_pred = scaler.inverse_transform(Y_test_pred)\n",
        "# Score_LSTM, Residual_tr, Residual_te = evaluation_trte(pd.DataFrame(Y_train), Y_train_pred.flatten(), \n",
        "#                                                       pd.DataFrame(Y_test), Y_test_pred.flatten(), graph_on=True)\n",
        "# display(Score_LSTM)\n",
        "\n",
        "# error analysis\n",
        "# error_analysis(Residual_te, ['Error'], pd.DataFrame(X_train.reshape(X_train.shape[0], X_train.shape[1])), graph_on=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "ER7-bjo80yZe",
        "outputId": "f40a465e-1a13-4837-a287-3fe305a558a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 4, 32)             5248      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4, 32)             0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 16)                3136      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,435\n",
            "Trainable params: 8,435\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "322/322 [==============================] - 20s 54ms/step - loss: 0.1465\n",
            "Epoch 2/5\n",
            "322/322 [==============================] - 10s 32ms/step - loss: 0.0762\n",
            "Epoch 3/5\n",
            "322/322 [==============================] - 10s 32ms/step - loss: 0.0614\n",
            "Epoch 4/5\n",
            "322/322 [==============================] - 10s 32ms/step - loss: 0.0523\n",
            "Epoch 5/5\n",
            "322/322 [==============================] - 10s 32ms/step - loss: 0.0467\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "# Y_train_pred = model.predict(X_train)\n",
        "Y_test_pred = model.predict(X_test)\n",
        "\n",
        "# # evaluation\n",
        "# result = model.evaluate(X_test_a, Y_test_pred)\n",
        "\n",
        "Y_test_pred\n",
        "# Y_test_pred[:,0].mean(), Y_test_pred[:,1].mean(), Y_test_pred[:,2].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwMMysGIkUb5",
        "outputId": "2caec6f8-1e6b-4ea0-88e2-478de9d482e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.7490121 , -0.09192742,  0.28116995],\n",
              "       [-0.0295599 ,  1.098648  , -0.03829005],\n",
              "       [ 0.00496428,  0.13168696,  0.84811777],\n",
              "       ...,\n",
              "       [ 0.7854265 ,  0.0175014 ,  0.24295655],\n",
              "       [ 0.0686049 ,  0.8146117 ,  0.09408709],\n",
              "       [-0.04260239,  0.07432953,  0.9169396 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1-kZMex3kUfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU\n",
        "# with tf.device('/device:GPU:0'):\n",
        "model = Sequential()\n",
        "model.add(GRU(32, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='relu'))\n",
        "model.add(Dropout(dropout_ratio)) \n",
        "# model.add(GRU(256, return_sequences=True, activation=\"relu\"))\n",
        "# model.add(Dropout(dropout_ratio)) \n",
        "# model.add(GRU(128, return_sequences=True, activation=\"relu\"))\n",
        "# model.add(Dropout(dropout_ratio)) \n",
        "model.add(GRU(16, return_sequences=False, activation=\"relu\"))\n",
        "model.add(Dropout(dropout_ratio)) \n",
        "model.add(Dense(3))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()\n",
        "model_fit = model.fit(X_train, Y_train, \n",
        "                      batch_size=batch_size, epochs=epoch,\n",
        "                      verbose=verbose)\n",
        "\n",
        "plt.plot(pd.DataFrame(model_fit.history))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# prediction\n",
        "Y_train_pred = model.predict(X_train)\n",
        "Y_test_pred = model.predict(X_test)\n",
        "\n",
        "# evaluation\n",
        "result = model.evaluate(X_test, Y_test_pred)\n",
        "# if scaler != []:\n",
        "#     Y_train = scaler.inverse_transform(Y_train)\n",
        "#     Y_train_pred = scaler.inverse_transform(Y_train_pred)\n",
        "#     Y_test = scaler.inverse_transform(Y_test)\n",
        "#     Y_test_pred = scaler.inverse_transform(Y_test_pred)\n",
        "# Score_GRU, Residual_tr, Residual_te = evaluation_trte(pd.DataFrame(Y_train), Y_train_pred, \n",
        "#                                                       pd.DataFrame(Y_test), Y_test_pred, graph_on=True)\n",
        "# display(Score_GRU)\n",
        "\n",
        "# # error analysis\n",
        "# error_analysis(Residual_te, ['Error'], pd.DataFrame(X_train.reshape(X_train.shape[0], X_train.shape[1])), graph_on=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "erHcdkv91cgG",
        "outputId": "01e5b45d-e550-48a6-cd18-c8cfad6c1f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 4, 32)             4032      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 32)             0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 16)                2400      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 6,483\n",
            "Trainable params: 6,483\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "300/300 [==============================] - 38s 91ms/step - loss: 0.1864\n",
            "Epoch 2/5\n",
            "300/300 [==============================] - 17s 58ms/step - loss: 0.0697\n",
            "Epoch 3/5\n",
            "300/300 [==============================] - 11s 37ms/step - loss: 0.0554\n",
            "Epoch 4/5\n",
            "300/300 [==============================] - 11s 36ms/step - loss: 0.0494\n",
            "Epoch 5/5\n",
            "300/300 [==============================] - 12s 42ms/step - loss: 0.0449\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 1s 3ms/step - loss: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "Y_train_pred = model.predict(X_train)\n",
        "# Y_test_pred = model.predict(X_test)\n",
        "\n",
        "# # evaluation\n",
        "# result = model.evaluate(X_test_a, Y_test_pred)\n",
        "\n",
        "Y_train_pred\n",
        "# Y_test_pred\n",
        "\n",
        "# Y_test_pred[:,0].mean(), Y_test_pred[:,1].mean(), Y_test_pred[:,2].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXDM1VSXkzvH",
        "outputId": "8bdbc517-3f97-4fa2-aca6-1e8eac5d26e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.0112829 , -0.03642473,  0.06247383],\n",
              "       [-0.02140309,  0.9427316 ,  0.0493685 ],\n",
              "       [ 0.05671174, -0.0120296 ,  0.93993187],\n",
              "       ...,\n",
              "       [ 0.9503317 , -0.11450075,  0.19628632],\n",
              "       [-0.03033249,  0.9014447 ,  0.07251298],\n",
              "       [ 0.26795328,  0.12299843,  0.6673869 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LgCMeGrkzyi",
        "outputId": "9558197f-f282-46c3-b9c4-bc780f40b02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.66666667, 0.        , 1.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.66666667, 1.        , 0.        , ..., 0.        ,\n",
              "         1.        , 0.        ],\n",
              "        [0.66666667, 0.5       , 1.        , ..., 0.        ,\n",
              "         0.8       , 0.        ]],\n",
              "\n",
              "       [[1.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [1.        , 1.        , 0.        , ..., 0.        ,\n",
              "         0.        , 1.        ],\n",
              "        [1.        , 0.5       , 1.        , ..., 0.        ,\n",
              "         1.        , 0.        ],\n",
              "        [0.73684211, 0.        , 0.        , ..., 0.        ,\n",
              "         0.8       , 0.        ]],\n",
              "\n",
              "       [[1.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.73684211, 1.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.73684211, 0.5       , 0.        , ..., 0.        ,\n",
              "         1.        , 0.        ],\n",
              "        [0.63157895, 0.        , 1.        , ..., 1.        ,\n",
              "         0.8       , 0.        ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.        , 1.        , 0.        , ..., 0.        ,\n",
              "         0.        , 1.        ],\n",
              "        [0.        , 0.5       , 1.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [1.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.66666667, 0.        , 1.        , ..., 0.        ,\n",
              "         0.        , 0.        ]],\n",
              "\n",
              "       [[1.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [1.        , 1.        , 0.        , ..., 0.        ,\n",
              "         0.        , 1.        ],\n",
              "        [1.        , 0.5       , 0.        , ..., 0.        ,\n",
              "         1.        , 0.        ],\n",
              "        [0.73684211, 0.        , 0.        , ..., 0.        ,\n",
              "         0.8       , 0.        ]],\n",
              "\n",
              "       [[0.26315789, 0.        , 0.        , ..., 0.        ,\n",
              "         0.2       , 0.        ],\n",
              "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [1.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.73684211, 1.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ]]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_load_test = load_agent('/contents/MyDrive/Colab_Notebooks/projects/NCPW/RL/agent/DQN_agent_[10_15_20_20]_test2.ptb')\n",
        "\n",
        "logs_test = []\n",
        "for _ in range(300):\n",
        "  log = json.loads(get_single_play_log(agent_load_test)['states'])\n",
        "  logs_test+=log\n",
        "\n",
        "df_test = pd.DataFrame(logs_test)     \n",
        "test_scaled = scaler.fit_transform(df_test)  \n",
        "\n",
        "X_test_test = []\n",
        "for index in range(len(test_scaled) - sequence):\n",
        "    X_test_test.append(test_scaled[index: index + sequence])\n",
        "\n",
        "## Retype and Reshape\n",
        "X_test_test = np.array(X_test_test)\n",
        "print('X_test_test:', X_test_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0RFxJmPe-RP",
        "outputId": "cecb110f-9d83-400b-94bf-4cfef7b83870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test_test: (12373, 4, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.predict(X_test_test)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbbFp6yYEiL_",
        "outputId": "6c450c43-aaa2-495f-b734-c51668246944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01226191,  1.0347848 ,  0.03124857],\n",
              "       [-0.00692205,  1.0568798 , -0.00246641],\n",
              "       [ 0.01154498,  1.0293908 ,  0.02055264],\n",
              "       ...,\n",
              "       [-0.0982015 ,  0.9838391 , -0.0101915 ],\n",
              "       [-0.01539788,  0.9665281 , -0.02346746],\n",
              "       [ 0.12531675,  1.0158839 , -0.07319714]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[:,0].mean(), result[:,1].mean(), result[:,2].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OiTT5jYfFq2",
        "outputId": "87dc3375-c097-4e26-b0c8-d8a6c407cdb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.013199004, 0.94996226, 0.06165413)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CodebyLpgIU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = None"
      ],
      "metadata": {
        "id": "Dt6hjuvk3wZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/contents/MyDrive/Colab_Notebooks/projects/NCPW/Classification/GRU_model_240')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KY2BV4W3xWr",
        "outputId": "56cd61d9-e7e2-45ed-c70d-4c6793b43053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /contents/MyDrive/Colab_Notebooks/projects/NCPW/Classification/GRU_model_240/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/contents/MyDrive/Colab_Notebooks/projects/NCPW/Classification/GRU_model_240')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg77XmqV4Lyq",
        "outputId": "12deeb23-7f28-49f2-baed-6841c7a3371e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FViL13m74fBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}